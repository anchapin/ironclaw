# Holon: AI-Powered PR Reviewer

**ID**: ai-pr-reviewer-1770664479110
**Level**: L1 (Substantiated)
**Kind**: system
**Decision Context**: code-quality-guardrails-decision-1770664479107
**Created**: 2025-02-09
**Verified**: 2025-02-09 (PASS)

## Content

### Method (Recipe)

Create an AI-powered GitHub Actions bot that reviews every PR with contextual, intelligent feedback:

**Custom AI Reviewer Script** (`.github/actions/ai-reviewer/index.js`):
- Analyzes PR diffs for bloat, duplication, verbosity, documentation gaps
- Uses Claude Sonnet 4 or GPT-4 for semantic understanding
- Posts review comments with specific suggestions and code examples
- References project context (PRD, CLAUDE.md, architecture principles)

**Configuration** (`.github/review-rules.md`):
- Defines quality rules aligned with IronClaw principles
- Context awareness of project architecture
- Feedback style guidelines (specific, educational, actionable)

### Expected Outcome

- **Intelligent Detection**: AI understands context, not just pattern matching
- **Actionable Feedback**: Specific suggestions with code examples
- **No False Positives**: AI understands project context and intent
- **Educational**: Teaches developers *why* changes matter
- **Adaptive**: Learns from project patterns over time

## Scope

**Applies to**: All pull requests
**Languages**: All (AI understands any code)
**Platform**: GitHub Actions + Anthropic Claude API
**Integration**: New workflow, posts review comments on PRs

## Rationale

```json
{
  "anomaly": "Static analysis tools miss context, generate false positives, can't understand intent",
  "approach": "Use AI to understand code context and provide intelligent, nuanced feedback",
  "alternatives_rejected": [
    "Static rules only (too rigid, many false positives)",
    "Human-only review (doesn't scale, inconsistent)",
    "SaaS code review tools (expensive, data privacy, generic rules)",
    "Multiple specialized tools (complexity to maintain)"
  ],
  "strengths": [
    "Understands context (PRD, architecture, patterns)",
    "Actionable feedback (specific examples, not just errors)",
    "Educational (teaches principles, not just rules)",
    "Adaptive (improves as it learns project patterns)",
    "Comprehensive (catches subtle issues static tools miss)",
    "Language-agnostic (works for Rust and Python equally)"
  ],
  "weaknesses": [
    "Cost: ~$0.03 per PR (Claude API costs)",
    "Latency: ~30-60 seconds for review",
    "API dependency (requires Anthropic API key in secrets)",
    "Non-blocking (comments vs hard gate)",
    "Potential for hallucinations (must verify suggestions)"
  ],
  "constraints": [
    "Must use secure API key storage (GitHub Secrets)",
    "Must provide confidence scores for suggestions",
    "Must not block PRs (advisory only)",
    "Must stay under $10/month API budget",
    "Must disclose AI usage in comments"
  ],
  "cost_estimate": {
    "per_pr": "$0.03 average (better than estimated $0.20)",
    "monthly": "$1.50 for 50 PRs/month",
    "justification": "Cheaper than human review time, catches issues automation can't"
  }
}
```

## Verification Summary

**Status**: âœ… SUBSTANTIATED (L1)
**Verification Date**: 2025-02-09
**Verdict**: PASS (Conditional)

**Key Findings**:
- All invariants respected (conditional on API dependency)
- Unique value: Contextual understanding, education, nuance
- Low cost (~$0.03/PR, better than estimated)
- Complementary to static analysis
- External API dependency acceptable for advisory dev tool

**Verification Record**: `.quint/knowledge/L1/ai-pr-reviewer-1770664479110-verification.md`

## Status

**Status**: substantiated (L1)
**Verification**: PASS (2025-02-09)
**Validation**: None yet
